1. Fine tune existing models on new genres (wave)
   - https://arxiv.org/abs/2208.08706
      - maybe add more tunable parameters
3. Fine tuning baroque counter point model, maybe RL (midi). Symbolic music generation with rule based systems (i.e. counterpoints)
4. Wave, testing GAN vs diffusion (personal implementation)


<h2>References and sources</h2>

Journal: https://transactions.ismir.net/collections/ai-and-musical-creativity

Waveform Audio Generation

https://sander.ai/2020/03/24/audio-generation.html

https://storage.googleapis.com/magentadata/papers/maestro/index.html

Models (state of the art)

MuseCoco https://ai-muzic.github.io/musecoco/

Deepbach https://github.com/Ghadjeres/DeepBach (can do both reharmonization and gnerate from scratch)

Folk rnn

MusicLM https://blog.research.google/2022/10/audiolm-language-modeling-approach-to.html

AudioLM

SingSong https://storage.googleapis.com/sing-song/index.html

Open AI Jukebox

Musenet: Similar approach to GPT-2 predict next token in a sequence.

https://magenta.tensorflow.org/piano-transformer (Transformer model)

Data sets:

https://lukewys.github.io/cocochorales/#overview (CocoChorales large dataset of generated 4 voice chorales with midi and audio)

https://magenta.tensorflow.org/datasets/maestro (Virtuoso Piano Music)