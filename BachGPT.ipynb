{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer,PreTrainedTokenizerFast\n",
    "\n",
    "# Download dataset - you can change it for your own dataset\n",
    "dataset = load_dataset(\"csv\", data_files=\"Datasets/jsfakes-bpe.csv\")\n",
    "# We had only \"train\" in the ds, so we can create a test and train split\n",
    "# Convert dataset to dataframe\n",
    "ds = dataset[\"train\"]\n",
    "df = ds.to_pandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = ds.train_test_split(test_size=0.1, shuffle=True)\n",
    "# Change for respective tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "\n",
    "# We need to specify the UNK token\n",
    "new_tokenizer = Tokenizer(model=WordLevel(unk_token=\"[UNK]\"))\n",
    "\n",
    "# Add pretokenizer\n",
    "from tokenizers.pre_tokenizers import WhitespaceSplit\n",
    "\n",
    "new_tokenizer.pre_tokenizer = WhitespaceSplit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d52ed5477a4a5b811019ac868431b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3655 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'tokenizers.Tokenizer' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Misc Coding Projects\\MusicAI\\MusicGen\\BachGPT.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m: outputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Create tokenized_dataset. We use map to pass each element of our dataset to tokenize and remove unnecessary columns.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m tokenized_datasets \u001b[39m=\u001b[39m raw_datasets\u001b[39m.\u001b[39;49mmap(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mlambda\u001b[39;49;00m x: tokenize(x), batched\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m tokenized_datasets\n",
      "File \u001b[1;32md:\\Misc Coding Projects\\MusicAI\\MusicGen\\.env\\Lib\\site-packages\\datasets\\dataset_dict.py:855\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    853\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[0;32m    854\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m--> 855\u001b[0m     {\n\u001b[0;32m    856\u001b[0m         k: dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[0;32m    857\u001b[0m             function\u001b[39m=\u001b[39;49mfunction,\n\u001b[0;32m    858\u001b[0m             with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[0;32m    859\u001b[0m             with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[0;32m    860\u001b[0m             input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[0;32m    861\u001b[0m             batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[0;32m    862\u001b[0m             batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    863\u001b[0m             drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[0;32m    864\u001b[0m             remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[0;32m    865\u001b[0m             keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[0;32m    866\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[0;32m    867\u001b[0m             cache_file_name\u001b[39m=\u001b[39;49mcache_file_names[k],\n\u001b[0;32m    868\u001b[0m             writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[0;32m    869\u001b[0m             features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[0;32m    870\u001b[0m             disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[0;32m    871\u001b[0m             fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[0;32m    872\u001b[0m             num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[0;32m    873\u001b[0m             desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[0;32m    874\u001b[0m         )\n\u001b[0;32m    875\u001b[0m         \u001b[39mfor\u001b[39;49;00m k, dataset \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems()\n\u001b[0;32m    876\u001b[0m     }\n\u001b[0;32m    877\u001b[0m )\n",
      "File \u001b[1;32md:\\Misc Coding Projects\\MusicAI\\MusicGen\\.env\\Lib\\site-packages\\datasets\\dataset_dict.py:856\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    853\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[0;32m    854\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m    855\u001b[0m     {\n\u001b[1;32m--> 856\u001b[0m         k: dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[0;32m    857\u001b[0m             function\u001b[39m=\u001b[39;49mfunction,\n\u001b[0;32m    858\u001b[0m             with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[0;32m    859\u001b[0m             with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[0;32m    860\u001b[0m             input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[0;32m    861\u001b[0m             batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[0;32m    862\u001b[0m             batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    863\u001b[0m             drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[0;32m    864\u001b[0m             remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[0;32m    865\u001b[0m             keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[0;32m    866\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[0;32m    867\u001b[0m             cache_file_name\u001b[39m=\u001b[39;49mcache_file_names[k],\n\u001b[0;32m    868\u001b[0m             writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[0;32m    869\u001b[0m             features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[0;32m    870\u001b[0m             disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[0;32m    871\u001b[0m             fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[0;32m    872\u001b[0m             num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[0;32m    873\u001b[0m             desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[0;32m    874\u001b[0m         )\n\u001b[0;32m    875\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[0;32m    876\u001b[0m     }\n\u001b[0;32m    877\u001b[0m )\n",
      "File \u001b[1;32md:\\Misc Coding Projects\\MusicAI\\MusicGen\\.env\\Lib\\site-packages\\datasets\\arrow_dataset.py:591\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    590\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 591\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    592\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    593\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[0;32m    594\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32md:\\Misc Coding Projects\\MusicAI\\MusicGen\\.env\\Lib\\site-packages\\datasets\\arrow_dataset.py:556\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[0;32m    550\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[0;32m    551\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[0;32m    552\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[0;32m    553\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[0;32m    554\u001b[0m }\n\u001b[0;32m    555\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 556\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    557\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    558\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32md:\\Misc Coding Projects\\MusicAI\\MusicGen\\.env\\Lib\\site-packages\\datasets\\arrow_dataset.py:3089\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3082\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3083\u001b[0m     \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[0;32m   3084\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[0;32m   3085\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3086\u001b[0m         total\u001b[39m=\u001b[39mpbar_total,\n\u001b[0;32m   3087\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   3088\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3089\u001b[0m         \u001b[39mfor\u001b[39;49;00m rank, done, content \u001b[39min\u001b[39;49;00m Dataset\u001b[39m.\u001b[39;49m_map_single(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdataset_kwargs):\n\u001b[0;32m   3090\u001b[0m             \u001b[39mif\u001b[39;49;00m done:\n\u001b[0;32m   3091\u001b[0m                 shards_done \u001b[39m+\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m\n",
      "File \u001b[1;32md:\\Misc Coding Projects\\MusicAI\\MusicGen\\.env\\Lib\\site-packages\\datasets\\arrow_dataset.py:3466\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3462\u001b[0m indices \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   3463\u001b[0m     \u001b[39mrange\u001b[39m(\u001b[39m*\u001b[39m(\u001b[39mslice\u001b[39m(i, i \u001b[39m+\u001b[39m batch_size)\u001b[39m.\u001b[39mindices(shard\u001b[39m.\u001b[39mnum_rows)))\n\u001b[0;32m   3464\u001b[0m )  \u001b[39m# Something simpler?\u001b[39;00m\n\u001b[0;32m   3465\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3466\u001b[0m     batch \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(\n\u001b[0;32m   3467\u001b[0m         batch,\n\u001b[0;32m   3468\u001b[0m         indices,\n\u001b[0;32m   3469\u001b[0m         check_same_num_examples\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(shard\u001b[39m.\u001b[39;49mlist_indexes()) \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[0;32m   3470\u001b[0m         offset\u001b[39m=\u001b[39;49moffset,\n\u001b[0;32m   3471\u001b[0m     )\n\u001b[0;32m   3472\u001b[0m \u001b[39mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[0;32m   3473\u001b[0m     \u001b[39mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[0;32m   3474\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3475\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Misc Coding Projects\\MusicAI\\MusicGen\\.env\\Lib\\site-packages\\datasets\\arrow_dataset.py:3345\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3343\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[0;32m   3344\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[1;32m-> 3345\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[0;32m   3346\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3347\u001b[0m     processed_inputs \u001b[39m=\u001b[39m {\n\u001b[0;32m   3348\u001b[0m         k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mkeys_to_format\n\u001b[0;32m   3349\u001b[0m     }\n",
      "\u001b[1;32md:\\Misc Coding Projects\\MusicAI\\MusicGen\\BachGPT.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m: outputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Create tokenized_dataset. We use map to pass each element of our dataset to tokenize and remove unnecessary columns.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m tokenized_datasets \u001b[39m=\u001b[39m raw_datasets\u001b[39m.\u001b[39mmap(\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mlambda\u001b[39;00m x: tokenize(x), batched\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m tokenized_datasets\n",
      "\u001b[1;32md:\\Misc Coding Projects\\MusicAI\\MusicGen\\BachGPT.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize\u001b[39m(element):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m   outputs \u001b[39m=\u001b[39m new_tokenizer(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m       element[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m       truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m#Removing element longer that context size, no effect in JSB\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m       max_length\u001b[39m=\u001b[39;49mcontext_length,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m       padding\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m   )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Misc%20Coding%20Projects/MusicAI/MusicGen/BachGPT.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m: outputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]}\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tokenizers.Tokenizer' object is not callable"
     ]
    }
   ],
   "source": [
    "# You can replace this, 2048 seems a good number here\n",
    "context_length = 2048\n",
    "\n",
    "# Function for tokenizing the dataset\n",
    "def tokenize(element):\n",
    "  outputs = new_tokenizer(\n",
    "      element[\"train\"],\n",
    "      truncation=True, #Removing element longer that context size, no effect in JSB\n",
    "      max_length=context_length,\n",
    "      padding=False\n",
    "  )\n",
    "  return {\"input_ids\": outputs[\"input_ids\"]}\n",
    "\n",
    "# Create tokenized_dataset. We use map to pass each element of our dataset to tokenize and remove unnecessary columns.\n",
    "tokenized_datasets = list(map(\n",
    "    lambda x: tokenize(x), new_ batched=True\n",
    "))\n",
    "\n",
    "tokenized_datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
